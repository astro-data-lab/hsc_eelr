{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a better colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='inferno', interpolation='none', origin='lower')\n",
    "\n",
    "# our code for source separation\n",
    "import scarlet\n",
    "import scarlet.display\n",
    "# code to detect sources\n",
    "import sep\n",
    "\n",
    "# to open fits files\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data path on local machine\n",
    "data_dir = '/home/czhao/Synced/Documents/PrincetonStuff/2019-20/spring/IW/hsc_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_list = Table.read('parent_sample/source_list.fits')\n",
    "# source_list = Table.read('good_ir_merged.fits')\n",
    "source_list = Table.read('parent_sample/EELR_HSCmag_from_SDSSspec.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find directory for source at RA/DEC\n",
    "\n",
    "def get_source_i(ra, dec):\n",
    "    d = (source_list['RA'] - ra)**2 + (source_list['DEC'] - dec)**2\n",
    "    i = np.argmin(d)\n",
    "    if d[i] * 3600 > 1:\n",
    "        print(\"Closest match more than 1 arcsec away: Proceed with caution!\")\n",
    "    return i\n",
    "\n",
    "# most prominent candidate\n",
    "# ra, dec=37.77, -3.75\n",
    "# source_i = get_source_i(ra, dec)\n",
    "\n",
    "source_i = 2\n",
    "\n",
    "source_id = int(source_list[source_i][\"OBJID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def get_images_and_psfs(source_id):\n",
    "    # open files of the source\n",
    "    bands = ['G', 'R', 'I', 'Z', 'Y']\n",
    "    images = []\n",
    "    psfs = []\n",
    "    for b in bands:\n",
    "        file = glob.glob(\"{}/{:05d}/cutout_HSC-{}_*_src_*.fits\".format(data_dir, source_id, b))[0]\n",
    "        hdulist = fits.open(file)\n",
    "        images.append(hdulist[1].data)\n",
    "        hdulist.close()\n",
    "\n",
    "        file = glob.glob(\"{}/{:05d}/psf_HSC-{}_*_src_*.fits\".format(data_dir, source_id, b))[0]\n",
    "        hdulist = fits.open(file)\n",
    "        psfs.append(hdulist[0].data)\n",
    "        hdulist.close()\n",
    "    images = (np.array(images)[:,40:-40,40:-40]).copy()\n",
    "\n",
    "    # pad PSFs to the same shape\n",
    "    psf_height = max(psf.shape[0] for psf in psfs)\n",
    "    psf_width = max(psf.shape[1] for psf in psfs)\n",
    "    psfs = np.stack([np.pad(psf, (((psf_height - psf.shape[0]) // 2,), ((psf_width - psf.shape[1]) // 2,)))\n",
    "                     for psf in psfs])\n",
    "    \n",
    "    return images, psfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, psfs = get_images_and_psfs(source_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get magnitude of line emitters\n",
    "def mag2amplitude(mags):\n",
    "    dlambda = np.array([.14, .14, .16, .13, .11])\n",
    "    fnu_Jy = 10**((48.6+mags)/-2.5)\n",
    "    photons_1Jy = 1.51e7 / dlambda\n",
    "    return photons_1Jy * fnu_Jy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Ai-Lei spectral decomposition tables\n",
    "# this will require a read-out method to work with other sources\n",
    "# mags = np.array([26.3652646789765, 23.73486734207137, 21.898052328748093, 28, 21.05645664757267])\n",
    "\n",
    "# mags = np.array([source_list[source_i][f\"speclineMag_{band.lower()}\"] for band in bands])\n",
    "\n",
    "mags = np.nan_to_num(source_list[source_i]['MAG_AB_LINEONLY'], nan=30.0)\n",
    "\n",
    "print(mags)\n",
    "\n",
    "# last element (Y band) appears untrustworthy\n",
    "band_mask = [0,0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect all sources in the image\n",
    "def makeCatalog(img):\n",
    "    detect = img.mean(axis=0)\n",
    "    bkg = sep.Background(detect)\n",
    "    #catalog = sep.extract(detect, 1.5, err=bkg.globalrms,deblend_nthresh=64,deblend_cont=3e-4)\n",
    "    catalog, segmap = sep.extract(detect, 1.2, err=bkg.globalrms,deblend_nthresh=64,deblend_cont=3e-4, segmentation_map=True)\n",
    "    bg_rms = np.array([sep.Background(band).globalrms for band in img])\n",
    "    return catalog, segmap, bg_rms\n",
    "\n",
    "def display_img(images, norm, catalog):\n",
    "    # make and image and label all sources\n",
    "    img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(img_rgb)\n",
    "    # Mark all of the sources from the detection cataog\n",
    "    for k, src in enumerate(catalog):\n",
    "        plt.text(src[\"x\"], src[\"y\"], str(k), color=\"w\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog, segmap, bg_rms = makeCatalog(images)\n",
    "# first define color stretch and convert 5 bands to RGB channels\n",
    "stretch = 1\n",
    "Q = 5\n",
    "norm = scarlet.display.AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "display_img(images, norm, catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display psfs\n",
    "psfs_min = min(psf.min() for psf in psfs)\n",
    "pnorm = scarlet.display.AsinhMapping(minimum=psfs_min, stretch=1e-2, Q=1)\n",
    "prgb = scarlet.display.img_to_rgb(psfs, norm=pnorm)\n",
    "plt.figure()\n",
    "plt.imshow(prgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Frame and Observation:\n",
    "model_psf = scarlet.PSF(partial(scarlet.psf.gaussian, sigma=.8), shape=(None, 8, 8))\n",
    "bands = ['g', 'r', 'i', 'z', 'y']\n",
    "\n",
    "frame = scarlet.Frame(images.shape, psfs=model_psf, channels=bands)\n",
    "\n",
    "# no weight maps, use flat background noise variance instead\n",
    "# weights = np.ones_like(images) / (bg_rms[:,None,None]**2)\n",
    "observation = scarlet.Observation(images, psfs=psfs, channels=bands).match(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEDConstraint(scarlet.Constraint):\n",
    "    def __init__(self, sed):\n",
    "        self._sed = sed\n",
    "\n",
    "    def __call__(self, X, step):\n",
    "        S = self._sed\n",
    "        # closest X that is in the direction of S\n",
    "        # allows for flux rescaling: only direction is constrained\n",
    "        if not np.ma.is_masked(S):\n",
    "            X[:] = np.maximum(np.dot(X, S) / np.dot(S, S) * S, 0)\n",
    "        else:\n",
    "            X_ = X[~S.mask]\n",
    "            S_ = S[~S.mask]\n",
    "            X[:][~S.mask] =  np.maximum(np.dot(X_, S_) / np.dot(S_, S_) * S_, 0)\n",
    "        return X\n",
    "    \n",
    "class RadialMaskConstraint(scarlet.Constraint):\n",
    "    def __init__(self, shape, pixel_center, R):\n",
    "        c, ny, nx = shape\n",
    "        dy = np.arange(ny) - pixel_center[0]\n",
    "        dx = np.arange(nx) - pixel_center[1]\n",
    "        dist2 = dy[:,None]**2 + dx[None,:]**2\n",
    "        self.mask = dist2 > R**2\n",
    "        \n",
    "    def __call__(self, X, step):\n",
    "        X[self.mask] = 0\n",
    "        X[:,:] = np.maximum(X, 0)\n",
    "        return X\n",
    "        \n",
    "    \n",
    "class EELRSource(scarlet.RandomSource):\n",
    "    \"\"\"Source to describe EELR\n",
    "    \n",
    "    It has a free-form morphology, possible constrained to be within R of the center\n",
    "    but its SED can be determined up to a constant.\n",
    "    \"\"\"\n",
    "    def __init__(self, frame, sky_coord, sed=None, R=None):\n",
    "        super().__init__(frame)\n",
    "        \n",
    "        center = np.array(frame.get_pixel(sky_coord), dtype=\"float\")\n",
    "        self.pixel_center = tuple(np.round(center).astype(\"int\"))\n",
    "        \n",
    "        if sed is not None:\n",
    "            self._parameters[0].constraint = SEDConstraint(sed)\n",
    "            self._parameters[0][:] = self._parameters[0].constraint(self._parameters[0], 0)\n",
    "        if R is not None:\n",
    "            self._parameters[1].constraint = RadialMaskConstraint(frame.shape, self.pixel_center, R)\n",
    "            self._parameters[1][:,:] = self._parameters[1].constraint(self._parameters[1], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_source(catalog, dim):\n",
    "    eelr_host_ind = -1\n",
    "    closest_distsq = dim[0]**2 + dim[1]**2\n",
    "    center = (dim[0] / 2, dim[1] / 2)\n",
    "    for k, src in enumerate(catalog):\n",
    "        distsq = (src['y'] - center[0])**2 + (src['x'] - center[1])**2\n",
    "        if distsq < closest_distsq:\n",
    "            eelr_host_ind = k\n",
    "            closest_distsq = distsq\n",
    "    return eelr_host_ind\n",
    "\n",
    "def create_sources(catalog, eelr_host_ind, mags, mask, frame, observation):\n",
    "    sources = []\n",
    "    for k, src in enumerate(catalog):\n",
    "        if k == eelr_host_ind:\n",
    "            sources.append(scarlet.MultiComponentSource(frame, (src['y'], src['x']), observation, thresh=0.2, shifting=True))\n",
    "\n",
    "            # set mag for EELR source\n",
    "            mags = np.ma.masked_array(mags, mask=mask)\n",
    "            eelr_sed = mag2amplitude(mags)\n",
    "            sources.append(EELRSource(frame, (src['y'],src['x']), sed=eelr_sed, R=None))\n",
    "        else:\n",
    "            sources.append(scarlet.ExtendedSource(frame, (src['y'],src['x']), observation, shifting=True, thresh=0.5))\n",
    "    return sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eelr_host_ind = get_center_source(catalog, (images.shape[1], images.shape[2]))\n",
    "print(eelr_host_ind)\n",
    "print(catalog[eelr_host_ind]['x'], catalog[eelr_host_ind]['y'])\n",
    "sources = create_sources(catalog, eelr_host_ind, mags, band_mask, frame, observation)\n",
    "blend = scarlet.Blend(sources, observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the fitter\n",
    "%time blend.fit(200, e_rel=1e-5)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend.loss), -blend.loss[-1]))\n",
    "plt.plot(-np.array(blend.loss))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_scene(sources, observation=observation, norm=norm, show_observed=True, show_rendered=True, show_residual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_sources(sources, observation, show_observed=True, show_rendered=True, norm=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = f\"{source_id:05d}_\"\n",
    "\n",
    "print(path_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_asinh_stretch(img):\n",
    "    stretch = 0.05\n",
    "    Q = 5\n",
    "    norm = scarlet.display.AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "    plt.imshow(scarlet.display.img_to_rgb(img, norm=norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_one_eelr_sample(catalog, eelr_host_ind, mags, mask, frame, observation):\n",
    "    sources = create_sources(catalog, eelr_host_ind, mags, mask, frame, observation)\n",
    "    blend = scarlet.Blend(sources, observation)\n",
    "    blend.fit(200, e_rel=1e-5)\n",
    "#     print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend.loss), -blend.loss[-1]))\n",
    "    \n",
    "    # EELR host and source and logL\n",
    "    return sources[eelr_host_ind], sources[eelr_host_ind+1], -blend.loss[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eelr_samples = []\n",
    "for _ in range(2):\n",
    "    eelr_samples.append(do_one_eelr_sample(catalog, eelr_host_ind, mags, band_mask, frame, observation)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_sources(eelr_samples, observation, show_observed=True, show_rendered=True, norm=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_snr(X):\n",
    "    sig = (X**2).mean(axis=0)\n",
    "    noise = X.var(axis=0)\n",
    "    snr = sig / noise\n",
    "    snr[sig==0] = 0\n",
    "    snr = np.nan_to_num(snr, nan=np.nanmax(snr))\n",
    "    return snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap of average (since multiple bands) SNR of each EELR pixel\n",
    "\n",
    "eelr_models = np.stack([sample.get_model() for sample in eelr_samples])\n",
    "\n",
    "snr_per_band = compute_snr(eelr_models)\n",
    "snr = snr_per_band.mean(axis=0)\n",
    "\n",
    "plt.imshow(snr)\n",
    "plt.colorbar()\n",
    "plt.savefig(f\"{path_base}model_snr.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap of average morphology\n",
    "\n",
    "eelr_morphs = np.stack([sample.morph for sample in eelr_samples])\n",
    "mean_morph = eelr_morphs.mean(axis=0)\n",
    "\n",
    "plt.imshow(mean_morph)\n",
    "plt.colorbar()\n",
    "plt.savefig(f\"{path_base}morph_avg.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap of morphology SNR\n",
    "\n",
    "morph_snr = compute_snr(eelr_morphs)\n",
    "\n",
    "plt.imshow(morph_snr)\n",
    "plt.colorbar()\n",
    "plt.savefig(f\"{path_base}morph_snr.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unmasked Y band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_unmasked_y_samples(catalog, eelr_host_ind, mags, samples_per_y, frame, observation):\n",
    "    unmasked_y_host_samples = []\n",
    "    unmasked_y_eelr_samples = []\n",
    "    unmasked_y_logL = []\n",
    "    for y in range(22, 27+1):\n",
    "        print(f\"y = {y}:\")\n",
    "        this_mags = mags\n",
    "        this_mags[4] = y\n",
    "        for i in range(samples_per_y):\n",
    "            host_sample, eelr_sample, logL = do_one_eelr_sample(catalog, eelr_host_ind, this_mags, [0, 0, 0, 0, 0], frame, observation)\n",
    "            unmasked_y_host_samples.append(host_sample)\n",
    "            unmasked_y_eelr_samples.append(eelr_sample)\n",
    "            unmasked_y_logL.append(logL)\n",
    "    return unmasked_y_host_samples, unmasked_y_eelr_samples, unmasked_y_logL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_y = 5\n",
    "unmasked_y_host_samples, unmasked_y_eelr_samples, unmasked_y_logL = get_unmasked_y_samples(catalog, eelr_host_ind, mags, samples_per_y, frame, observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subsample = [unmasked_y_eelr_samples[i] for i in range(0, len(unmasked_y_eelr_samples), samples_per_y)]\n",
    "scarlet.display.show_sources(subsample, observation, show_observed=True, show_rendered=True, norm=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean_and_var(samples, weights):\n",
    "    # Computes Bayes mean and variance\n",
    "#     samples = np.stack(samples)\n",
    "    mean = np.average(samples, axis=0, weights=weights)\n",
    "    var = (weights * np.moveaxis((samples - mean)**2, 0, 2)).sum(axis=-1) / weights.sum()\n",
    "    return mean, var\n",
    "\n",
    "def get_outliers(arr, thresh=5):\n",
    "    # Returns mask of outliers that are more than thresh below the median\n",
    "    mask = np.zeros(arr.shape)\n",
    "    last_size = -1\n",
    "    cur_size = 0\n",
    "    while cur_size > last_size:\n",
    "        last_size = cur_size\n",
    "        med = np.median(arr)\n",
    "        mask = arr < med - thresh\n",
    "        cur_size = np.count_nonzero(mask)\n",
    "    return mask\n",
    "\n",
    "def zero_borders(X):\n",
    "    X[0, :] = 0\n",
    "    X[-1, :] = 0\n",
    "    X[:, 0] = 0\n",
    "    X[:, -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_morphs = np.array([sample.components[1].morph for sample in unmasked_y_host_samples])\n",
    "# host_morphs = np.array([sample.morph for sample in unmasked_y_host_samples])\n",
    "eelr_morphs = np.array([sample.morph for sample in unmasked_y_eelr_samples])\n",
    "unmasked_y_logL = np.array(unmasked_y_logL)\n",
    "\n",
    "# Repeatedly drop likelihoods that are more than five orders of magnitude less than median\n",
    "mask = get_outliers(np.array(unmasked_y_logL))\n",
    "print(f\"Dropping {np.count_nonzero(mask)} samples.\")\n",
    "scaled_likelihoods = np.exp(unmasked_y_logL[~mask] - min(unmasked_y_logL[~mask]))\n",
    "scaled_likelihoods /= scaled_likelihoods.min()\n",
    "host_morphs = host_morphs[~mask]\n",
    "eelr_morphs = eelr_morphs[~mask]\n",
    "\n",
    "host_bayes_mean, host_bayes_var = weighted_mean_and_var(host_morphs, scaled_likelihoods)\n",
    "eelr_bayes_mean, eelr_bayes_var = weighted_mean_and_var(eelr_morphs, scaled_likelihoods)\n",
    "\n",
    "# zero out borders to remove artifacts due to PSF\n",
    "zero_borders(host_bayes_mean)\n",
    "zero_borders(eelr_bayes_mean)\n",
    "\n",
    "# TODO: is it expected that the likelihoods vary by tens of orders of magnitude?\n",
    "\n",
    "# plt.imshow(host_bayes_mean)\n",
    "plot_asinh_stretch(host_bayes_mean)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# plt.imshow(host_bayes_var)\n",
    "plot_asinh_stretch(host_bayes_var)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(eelr_bayes_mean)\n",
    "plt.colorbar()\n",
    "plt.savefig(f\"{path_base}morph_bayes_mean.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(eelr_bayes_var)\n",
    "plt.colorbar()\n",
    "plt.savefig(f\"{path_base}morph_bayes_var.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, morph in enumerate(eelr_morphs):\n",
    "    print(i)\n",
    "    plt.imshow(morph)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EELR Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ellipse(morph):\n",
    "    bkg = sep.Background(morph)\n",
    "    objects = sep.extract(morph, 1.2, err=bkg.globalrms)\n",
    "    if len(objects) != 1:\n",
    "        print(f\"Detected {len(objects)} objects in host!\")\n",
    "    i = max(list(range(len(objects))), key=lambda i: objects[\"cflux\"][i])\n",
    "    return objects[\"x\"][i], objects[\"y\"][i], objects[\"a\"][i], objects[\"b\"][i], objects[\"theta\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "host_ellipse = fit_ellipse(host_bayes_mean)\n",
    "print(host_ellipse)\n",
    "\n",
    "plot_asinh_stretch(host_bayes_mean)\n",
    "e = Ellipse(xy=(host_ellipse[0], host_ellipse[1]),\n",
    "                width=6*host_ellipse[2],\n",
    "                height=6*host_ellipse[3],\n",
    "                angle=host_ellipse[4] * 180. / np.pi)\n",
    "e.set_facecolor('none')\n",
    "e.set_edgecolor('red')\n",
    "plt.gca().add_artist(e)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eelr_bayes_mean.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# TODO: dynamically set this threshold\n",
    "thresh = 1\n",
    "center_x = host_bayes_mean.shape[1] / 2 - 0.5\n",
    "center_y = host_bayes_mean.shape[0] / 2 - 0.5\n",
    "thetas = []\n",
    "for r in range(eelr_bayes_mean.shape[0]):\n",
    "    for c in range(eelr_bayes_mean.shape[1]):\n",
    "        if eelr_bayes_mean[r, c] > thresh:\n",
    "            x = c - center_x\n",
    "            y = r - center_y\n",
    "            theta = math.atan2(y, x) - host_ellipse[4]\n",
    "            theta = theta * 180 / math.pi\n",
    "            if theta < 0:\n",
    "                theta += 360\n",
    "            thetas.append(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(thetas)\n",
    "plt.xlabel(\"Theta (°)\")\n",
    "plt.ylabel(\"Number of Pixels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polar_projection(img, center, Rmax=None, resolution=12):\n",
    "    \"\"\"Evaluate img at the location of polar grid coordinates\n",
    "    This method doesn't resample `img` on the polar grid, it merely\n",
    "    transforms the coordinates and picks the nearest pixel.\n",
    "    For resolved features, this is an acceptable approximation\n",
    "    \"\"\"\n",
    "    lims = img.shape\n",
    "    if Rmax is None:\n",
    "        Rmax = np.sqrt(lims[0]**2 + lims[1]**2)\n",
    "    R, P = np.meshgrid(np.linspace(0, Rmax, resolution, dtype=np.float), np.linspace(-np.pi, np.pi, resolution))\n",
    "    Y = np.round(R * np.sin(P)).astype('int') + center[0]\n",
    "    X = np.round(R * np.cos(P)).astype('int') + center[1]\n",
    "    YX = np.dstack((Y,X))\n",
    "    polar = np.array([[ img[tuple(coord)] for coord in YX[i]] for i in range(len(YX))]).T\n",
    "    return polar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eelr_polar = polar_projection(eelr_bayes_mean,\n",
    "                              (host_bayes_mean.shape[0] // 2, host_bayes_mean.shape[1] // 2),\n",
    "                              min(eelr_bayes_mean.shape[0] // 2 - 1, eelr_bayes_mean.shape[1] // 2 - 1))\n",
    "angle_intensities = eelr_polar.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "def get_cyclic_peak_inds(arr):\n",
    "    \"\"\"Finds peaks in a cyclic array.\"\"\"\n",
    "    prom_thresh = 0.3 * (arr.max() - arr.min())  # min prominence of peaks\n",
    "    dist_thresh = len(arr) // 2 - 1  # min distance between peaks\n",
    "    flattened_peaks, props = find_peaks(arr, prominence=prom_thresh, distance=dist_thresh)\n",
    "#     print(flattened_peaks, props)\n",
    "    if len(flattened_peaks) == 0:\n",
    "        return np.array([])\n",
    "    # rotate so that first peak is at front\n",
    "    roll = -flattened_peaks[0] + 3\n",
    "    rotated = np.roll(arr, roll)\n",
    "    rotated_peaks, props = find_peaks(rotated, prominence=prom_thresh, distance=dist_thresh)\n",
    "    cyclic_peaks = (rotated_peaks - roll) % len(arr)\n",
    "    return np.sort(cyclic_peaks)\n",
    "\n",
    "def plot_with_peaks(arr, peak_inds):\n",
    "    bar_colors = np.array([\"blue\"] * len(arr))\n",
    "    bar_colors[peak_inds] = \"red\"\n",
    "    plt.bar(np.linspace(-np.pi, np.pi, len(arr)), arr, color=bar_colors, width=2*np.pi/len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclic_peak_inds = get_cyclic_peak_inds(angle_intensities)\n",
    "print(cyclic_peak_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_peaks(angle_intensities, cyclic_peak_inds)\n",
    "plt.savefig(f\"{path_base}angle_intensities.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stretch = 1\n",
    "Q = 5\n",
    "norm = scarlet.display.AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "bands = ['g', 'r', 'i', 'z', 'y']\n",
    "model_psf = scarlet.PSF(partial(scarlet.psf.gaussian, sigma=.8), shape=(None, 8, 8))\n",
    "\n",
    "jetlikes = []\n",
    "\n",
    "for source_i in range(len(source_list)):\n",
    "    # load in source\n",
    "    source_id = int(source_list[source_i][\"OBJID\"])\n",
    "    print(\"Source\", source_id)\n",
    "    images, psfs = get_images_and_psfs(source_id)\n",
    "    catalog, segmap, bg_rms = makeCatalog(images)\n",
    "    display_img(images, norm, catalog)\n",
    "    mags = np.nan_to_num(source_list[source_i]['MAG_AB_LINEONLY'], nan=30.0)\n",
    "\n",
    "    # define scarlet frame and observation\n",
    "    frame = scarlet.Frame(images.shape, psfs=model_psf, channels=bands)\n",
    "    observation = scarlet.Observation(images, psfs=psfs, channels=bands).match(frame)\n",
    "\n",
    "    # sampling\n",
    "    samples_per_y = 3\n",
    "    eelr_host_ind = get_center_source(catalog, (images.shape[1], images.shape[2]))\n",
    "    unmasked_y_host_samples, unmasked_y_eelr_samples, unmasked_y_logL = get_unmasked_y_samples(catalog, eelr_host_ind, mags, samples_per_y, frame, observation)\n",
    "\n",
    "    # morphology Bayes mean and variance\n",
    "    host_morphs = np.array([sample.components[1].morph for sample in unmasked_y_host_samples])\n",
    "    # host_morphs = np.array([sample.morph for sample in unmasked_y_host_samples])\n",
    "    eelr_morphs = np.array([sample.morph for sample in unmasked_y_eelr_samples])\n",
    "    unmasked_y_logL = np.array(unmasked_y_logL)\n",
    "    mask = get_outliers(np.array(unmasked_y_logL))\n",
    "    scaled_likelihoods = np.exp(unmasked_y_logL[~mask] - min(unmasked_y_logL[~mask]))\n",
    "    scaled_likelihoods /= scaled_likelihoods.min()\n",
    "    host_morphs = host_morphs[~mask]\n",
    "    eelr_morphs = eelr_morphs[~mask]\n",
    "    host_bayes_mean, host_bayes_var = weighted_mean_and_var(host_morphs, scaled_likelihoods)\n",
    "    eelr_bayes_mean, eelr_bayes_var = weighted_mean_and_var(eelr_morphs, scaled_likelihoods)\n",
    "    plt.imshow(eelr_bayes_mean)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    # zero out borders to remove artifacts due to PSF\n",
    "    zero_borders(host_bayes_mean)\n",
    "    zero_borders(eelr_bayes_mean)\n",
    "\n",
    "    # EELR angle intensities\n",
    "    eelr_polar = polar_projection(eelr_bayes_mean,\n",
    "                                  (host_bayes_mean.shape[0] // 2, host_bayes_mean.shape[1] // 2),\n",
    "                                  min(eelr_bayes_mean.shape[0] // 2 - 1, eelr_bayes_mean.shape[1] // 2 - 1))\n",
    "    angle_intensities = eelr_polar.sum(axis=0)\n",
    "    plt.bar(np.linspace(-np.pi, np.pi, eelr_polar.shape[1]), angle_intensities)\n",
    "    plt.show()\n",
    "\n",
    "    # peaks in angle space\n",
    "    cyclic_peak_inds = get_cyclic_peak_inds(angle_intensities)\n",
    "    print(cyclic_peak_inds)\n",
    "    if len(cyclic_peak_inds == 2):\n",
    "        jetlikes.append(source_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jetlikes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
