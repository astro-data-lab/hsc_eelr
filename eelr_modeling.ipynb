{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "# for parallel computing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a better colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='inferno', interpolation='none', origin='lower')\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# our code for source separation\n",
    "import scarlet\n",
    "import scarlet.display\n",
    "# code to detect sources\n",
    "import sep\n",
    "\n",
    "# to open fits files\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data path on local machine\n",
    "data_dir = '/home/czhao/Synced/Documents/PrincetonStuff/2019-20/spring/IW/hsc_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_list = Table.read('parent_sample/source_list.fits')\n",
    "# source_list = Table.read('good_ir_merged.fits')\n",
    "source_list = Table.read('parent_sample/EELR_HSCmag_from_SDSSspec.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find directory for source at RA/DEC\n",
    "\n",
    "def get_source_i(ra, dec):\n",
    "    d = (source_list['RA'] - ra)**2 + (source_list['DEC'] - dec)**2\n",
    "    i = np.argmin(d)\n",
    "    if d[i] * 3600 > 1:\n",
    "        print(\"Closest match more than 1 arcsec away: Proceed with caution!\")\n",
    "    return i\n",
    "\n",
    "# most prominent candidate\n",
    "# ra, dec=37.77, -3.75\n",
    "# source_i = get_source_i(ra, dec)\n",
    "\n",
    "source_i = 2\n",
    "\n",
    "source_id = int(source_list[source_i][\"OBJID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def get_images_and_psfs(source_id):\n",
    "    # open files of the source\n",
    "    bands = ['G', 'R', 'I', 'Z', 'Y']\n",
    "    images = []\n",
    "    psfs = []\n",
    "    for b in bands:\n",
    "        file = glob.glob(\"{}/{:05d}/cutout_HSC-{}_*_src_*.fits\".format(data_dir, source_id, b))[0]\n",
    "        hdulist = fits.open(file)\n",
    "        images.append(hdulist[1].data)\n",
    "        hdulist.close()\n",
    "\n",
    "        file = glob.glob(\"{}/{:05d}/psf_HSC-{}_*_src_*.fits\".format(data_dir, source_id, b))[0]\n",
    "        hdulist = fits.open(file)\n",
    "        psfs.append(hdulist[0].data)\n",
    "        hdulist.close()\n",
    "    images = (np.array(images)[:,40:-40,40:-40]).copy()\n",
    "\n",
    "    # pad PSFs to the same shape\n",
    "    psf_height = max(psf.shape[0] for psf in psfs)\n",
    "    psf_width = max(psf.shape[1] for psf in psfs)\n",
    "    psfs = np.stack([np.pad(psf, (((psf_height - psf.shape[0]) // 2,), ((psf_width - psf.shape[1]) // 2,)))\n",
    "                     for psf in psfs])\n",
    "    \n",
    "    return images, psfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, psfs = get_images_and_psfs(source_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get magnitude of line emitters\n",
    "def mag2amplitude(mags):\n",
    "    dlambda = np.array([.14, .14, .16, .13, .11])\n",
    "    fnu_Jy = 10**((48.6+mags)/-2.5)\n",
    "    photons_1Jy = 1.51e7 / dlambda\n",
    "    return photons_1Jy * fnu_Jy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Ai-Lei spectral decomposition tables\n",
    "# this will require a read-out method to work with other sources\n",
    "# mags = np.array([26.3652646789765, 23.73486734207137, 21.898052328748093, 28, 21.05645664757267])\n",
    "\n",
    "# mags = np.array([source_list[source_i][f\"speclineMag_{band.lower()}\"] for band in bands])\n",
    "\n",
    "mags = np.nan_to_num(source_list[source_i]['MAG_AB_LINEONLY'], nan=30.0)\n",
    "\n",
    "print(mags)\n",
    "\n",
    "# last element (Y band) appears untrustworthy\n",
    "band_mask = [0,0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect all sources in the image\n",
    "def makeCatalog(img):\n",
    "    detect = img.mean(axis=0)\n",
    "    bkg = sep.Background(detect)\n",
    "    #catalog = sep.extract(detect, 1.5, err=bkg.globalrms,deblend_nthresh=64,deblend_cont=3e-4)\n",
    "    catalog, segmap = sep.extract(detect, 1.2, err=bkg.globalrms,deblend_nthresh=64,deblend_cont=3e-4, segmentation_map=True)\n",
    "    bg_rms = np.array([sep.Background(band).globalrms for band in img])\n",
    "    return catalog, segmap, bg_rms\n",
    "\n",
    "def display_img(images, norm, catalog, ax=None):\n",
    "    # make and image and label all sources\n",
    "    img_rgb = scarlet.display.img_to_rgb(images, norm=norm)\n",
    "\n",
    "    if ax is None:\n",
    "        plt.figure(figsize=(6,6))\n",
    "        ax = plt.gca()\n",
    "    ax.imshow(img_rgb)\n",
    "    # Mark all of the sources from the detection cataog\n",
    "    for k, src in enumerate(catalog):\n",
    "        ax.text(src[\"x\"], src[\"y\"], str(k), color=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog, segmap, bg_rms = makeCatalog(images)\n",
    "# first define color stretch and convert 5 bands to RGB channels\n",
    "stretch = 1\n",
    "Q = 5\n",
    "norm = scarlet.display.AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "display_img(images, norm, catalog)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display psfs\n",
    "psfs_min = min(psf.min() for psf in psfs)\n",
    "pnorm = scarlet.display.AsinhMapping(minimum=psfs_min, stretch=1e-2, Q=1)\n",
    "prgb = scarlet.display.img_to_rgb(psfs, norm=pnorm)\n",
    "plt.figure()\n",
    "plt.imshow(prgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Frame and Observation:\n",
    "model_psf = scarlet.PSF(partial(scarlet.psf.gaussian, sigma=.8), shape=(None, 8, 8))\n",
    "bands = ['g', 'r', 'i', 'z', 'y']\n",
    "\n",
    "frame = scarlet.Frame(images.shape, psfs=model_psf, channels=bands)\n",
    "\n",
    "# no weight maps, use flat background noise variance instead\n",
    "# weights = np.ones_like(images) / (bg_rms[:,None,None]**2)\n",
    "observation = scarlet.Observation(images, psfs=psfs, channels=bands).match(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEDConstraint(scarlet.Constraint):\n",
    "    def __init__(self, sed):\n",
    "        self._sed = sed\n",
    "\n",
    "    def __call__(self, X, step):\n",
    "        S = self._sed\n",
    "        # closest X that is in the direction of S\n",
    "        # allows for flux rescaling: only direction is constrained\n",
    "        if not np.ma.is_masked(S):\n",
    "            X[:] = np.maximum(np.dot(X, S) / np.dot(S, S) * S, 0)\n",
    "        else:\n",
    "            X_ = X[~S.mask]\n",
    "            S_ = S[~S.mask]\n",
    "            X[:][~S.mask] =  np.maximum(np.dot(X_, S_) / np.dot(S_, S_) * S_, 0)\n",
    "        return X\n",
    "    \n",
    "class RadialMaskConstraint(scarlet.Constraint):\n",
    "    def __init__(self, shape, pixel_center, R):\n",
    "        c, ny, nx = shape\n",
    "        dy = np.arange(ny) - pixel_center[0]\n",
    "        dx = np.arange(nx) - pixel_center[1]\n",
    "        dist2 = dy[:,None]**2 + dx[None,:]**2\n",
    "        self.mask = dist2 > R**2\n",
    "        \n",
    "    def __call__(self, X, step):\n",
    "        X[self.mask] = 0\n",
    "        X[:,:] = np.maximum(X, 0)\n",
    "        return X\n",
    "        \n",
    "    \n",
    "class EELRSource(scarlet.RandomSource):\n",
    "    \"\"\"Source to describe EELR\n",
    "    \n",
    "    It has a free-form morphology, possible constrained to be within R of the center\n",
    "    but its SED can be determined up to a constant.\n",
    "    \"\"\"\n",
    "    def __init__(self, frame, sky_coord, sed=None, R=None):\n",
    "        super().__init__(frame)\n",
    "        \n",
    "        center = np.array(frame.get_pixel(sky_coord), dtype=\"float\")\n",
    "        self.pixel_center = tuple(np.round(center).astype(\"int\"))\n",
    "        \n",
    "        if sed is not None:\n",
    "            self._parameters[0].constraint = SEDConstraint(sed)\n",
    "            self._parameters[0][:] = self._parameters[0].constraint(self._parameters[0], 0)\n",
    "        if R is not None:\n",
    "            self._parameters[1].constraint = RadialMaskConstraint(frame.shape, self.pixel_center, R)\n",
    "            self._parameters[1][:,:] = self._parameters[1].constraint(self._parameters[1], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_source(catalog, dim):\n",
    "    eelr_host_ind = -1\n",
    "    closest_distsq = dim[0]**2 + dim[1]**2\n",
    "    center = (dim[0] / 2, dim[1] / 2)\n",
    "    for k, src in enumerate(catalog):\n",
    "        distsq = (src['y'] - center[0])**2 + (src['x'] - center[1])**2\n",
    "        if distsq < closest_distsq:\n",
    "            eelr_host_ind = k\n",
    "            closest_distsq = distsq\n",
    "    return eelr_host_ind\n",
    "\n",
    "def create_sources(catalog, eelr_host_ind, mags, mask, frame, observation):\n",
    "    sources = []\n",
    "    for k, src in enumerate(catalog):\n",
    "        if k == eelr_host_ind:\n",
    "            sources.append(scarlet.MultiComponentSource(frame, (src['y'], src['x']), observation, thresh=0.2, shifting=True))\n",
    "\n",
    "            # set mag for EELR source\n",
    "            mags = np.ma.masked_array(mags, mask=mask)\n",
    "            eelr_sed = mag2amplitude(mags)\n",
    "            sources.append(EELRSource(frame, (src['y'],src['x']), sed=eelr_sed, R=None))\n",
    "        else:\n",
    "            sources.append(scarlet.ExtendedSource(frame, (src['y'],src['x']), observation, shifting=True, thresh=0.5))\n",
    "    return sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eelr_host_ind = get_center_source(catalog, (images.shape[1], images.shape[2]))\n",
    "print(eelr_host_ind)\n",
    "print(catalog[eelr_host_ind]['x'], catalog[eelr_host_ind]['y'])\n",
    "sources = create_sources(catalog, eelr_host_ind, mags, band_mask, frame, observation)\n",
    "blend = scarlet.Blend(sources, observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the fitter\n",
    "%time blend.fit(200, e_rel=1e-5)\n",
    "print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend.loss), -blend.loss[-1]))\n",
    "plt.plot(-np.array(blend.loss))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('log-Likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_scene(sources, observation=observation, norm=norm, show_observed=True, show_rendered=True, show_residual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_sources(sources, observation, show_observed=True, show_rendered=True, norm=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = f\"{source_id:05d}_\"\n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_asinh_stretch(img):\n",
    "    stretch = 0.05\n",
    "    Q = 5\n",
    "    norm = scarlet.display.AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "    plt.imshow(scarlet.display.img_to_rgb(img, norm=norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_one_eelr_sample(catalog, eelr_host_ind, mags, mask, frame, observation):\n",
    "    sources = create_sources(catalog, eelr_host_ind, mags, mask, frame, observation)\n",
    "    blend = scarlet.Blend(sources, observation)\n",
    "    blend.fit(200, e_rel=1e-5)\n",
    "#     print(\"scarlet ran for {0} iterations to logL = {1}\".format(len(blend.loss), -blend.loss[-1]))\n",
    "    \n",
    "    # EELR host and source and logL\n",
    "    return sources[eelr_host_ind], sources[eelr_host_ind+1], -blend.loss[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eelr_samples = []\n",
    "for _ in range(2):\n",
    "    eelr_samples.append(do_one_eelr_sample(catalog, eelr_host_ind, mags, band_mask, frame, observation)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet.display.show_sources(eelr_samples, observation, show_observed=True, show_rendered=True, norm=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_snr(X):\n",
    "    sig = (X**2).mean(axis=0)\n",
    "    noise = X.var(axis=0)\n",
    "    snr = sig / noise\n",
    "    snr[sig==0] = 0\n",
    "    snr = np.nan_to_num(snr, nan=np.nanmax(snr))\n",
    "    return snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap of average (since multiple bands) SNR of each EELR pixel\n",
    "\n",
    "eelr_models = np.stack([sample.get_model() for sample in eelr_samples])\n",
    "\n",
    "snr_per_band = compute_snr(eelr_models)\n",
    "snr = snr_per_band.mean(axis=0)\n",
    "\n",
    "plt.imshow(snr)\n",
    "plt.colorbar()\n",
    "plt.savefig(f\"{prefix}model_snr.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap of average morphology\n",
    "\n",
    "eelr_morphs = np.stack([sample.morph for sample in eelr_samples])\n",
    "mean_morph = eelr_morphs.mean(axis=0)\n",
    "\n",
    "plt.imshow(mean_morph)\n",
    "plt.colorbar()\n",
    "plt.savefig(f\"{prefix}morph_avg.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap of morphology SNR\n",
    "\n",
    "morph_snr = compute_snr(eelr_morphs)\n",
    "\n",
    "plt.imshow(morph_snr)\n",
    "plt.colorbar()\n",
    "plt.savefig(f\"{prefix}morph_snr.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unmasked Y band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_unmasked_y_samples(catalog, eelr_host_ind, mags, num_samples, frame, observation):\n",
    "    unmasked_y_host_samples = []\n",
    "    unmasked_y_eelr_samples = []\n",
    "    unmasked_y_logL = []\n",
    "    for _ in range(num_samples):\n",
    "        y = 22 + np.random.random() * (27 - 22)\n",
    "#         print(f\"y = {y}:\")\n",
    "        this_mags = mags\n",
    "        this_mags[4] = y\n",
    "        host_sample, eelr_sample, logL = do_one_eelr_sample(catalog, eelr_host_ind, this_mags, [0, 0, 0, 0, 0], frame, observation)\n",
    "        unmasked_y_host_samples.append(host_sample)\n",
    "        unmasked_y_eelr_samples.append(eelr_sample)\n",
    "        unmasked_y_logL.append(logL)\n",
    "    return unmasked_y_host_samples, unmasked_y_eelr_samples, unmasked_y_logL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 20\n",
    "unmasked_y_host_samples, unmasked_y_eelr_samples, unmasked_y_logL = get_unmasked_y_samples(catalog, eelr_host_ind, mags, num_samples, frame, observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subsample = [unmasked_y_eelr_samples[i] for i in range(5)]\n",
    "scarlet.display.show_sources(subsample, observation, show_observed=True, show_rendered=True, norm=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean_and_var(samples, weights):\n",
    "    # Computes Bayes mean and variance\n",
    "#     samples = np.stack(samples)\n",
    "    mean = np.average(samples, axis=0, weights=weights)\n",
    "    var = (weights * np.moveaxis((samples - mean)**2, 0, 2)).sum(axis=-1) / weights.sum()\n",
    "    return mean, var\n",
    "\n",
    "def get_outliers(arr, thresh=5):\n",
    "    # Returns mask of outliers that are more than thresh below the median\n",
    "    mask = np.zeros(arr.shape)\n",
    "    last_size = -1\n",
    "    cur_size = 0\n",
    "    while cur_size > last_size:\n",
    "        last_size = cur_size\n",
    "        med = np.median(arr)\n",
    "        mask = arr < med - thresh\n",
    "        cur_size = np.count_nonzero(mask)\n",
    "    return mask\n",
    "\n",
    "def zero_borders(X):\n",
    "    X[0, :] = 0\n",
    "    X[-1, :] = 0\n",
    "    X[:, 0] = 0\n",
    "    X[:, -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_morphs = np.array([sample.components[1].morph for sample in unmasked_y_host_samples])\n",
    "# host_morphs = np.array([sample.morph for sample in unmasked_y_host_samples])\n",
    "eelr_morphs = np.array([sample.morph for sample in unmasked_y_eelr_samples])\n",
    "unmasked_y_logL = np.array(unmasked_y_logL)\n",
    "\n",
    "# Repeatedly drop likelihoods that are more than five orders of magnitude less than median\n",
    "mask = get_outliers(np.array(unmasked_y_logL))\n",
    "print(f\"Dropping {np.count_nonzero(mask)} samples.\")\n",
    "scaled_likelihoods = np.exp(unmasked_y_logL[~mask] - min(unmasked_y_logL[~mask]))\n",
    "scaled_likelihoods /= scaled_likelihoods.min()\n",
    "host_morphs = host_morphs[~mask]\n",
    "eelr_morphs = eelr_morphs[~mask]\n",
    "\n",
    "host_bayes_mean, host_bayes_var = weighted_mean_and_var(host_morphs, scaled_likelihoods)\n",
    "eelr_bayes_mean, eelr_bayes_var = weighted_mean_and_var(eelr_morphs, scaled_likelihoods)\n",
    "\n",
    "# zero out borders to remove artifacts due to PSF\n",
    "zero_borders(host_bayes_mean)\n",
    "zero_borders(eelr_bayes_mean)\n",
    "\n",
    "# low pass filter\n",
    "eelr_bayes_mean_filtered = gaussian_filter(eelr_bayes_mean, sigma=2)\n",
    "\n",
    "# TODO: is it expected that the likelihoods vary by tens of orders of magnitude?\n",
    "\n",
    "# plt.imshow(host_bayes_mean)\n",
    "plot_asinh_stretch(host_bayes_mean)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# plt.imshow(host_bayes_var)\n",
    "plot_asinh_stretch(host_bayes_var)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(eelr_bayes_mean)\n",
    "plt.colorbar()\n",
    "plt.savefig(f\"{prefix}morph_bayes_mean.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(eelr_bayes_mean_filtered)\n",
    "plt.colorbar()\n",
    "plt.savefig(f\"{prefix}morph_bayes_mean_filtered.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(eelr_bayes_var)\n",
    "plt.colorbar()\n",
    "plt.savefig(f\"{prefix}morph_bayes_var.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, morph in enumerate(eelr_morphs):\n",
    "    print(i)\n",
    "    plt.imshow(morph)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EELR Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ellipse(morph):\n",
    "    bkg = sep.Background(morph)\n",
    "    objects = sep.extract(morph, 1.2, err=bkg.globalrms)\n",
    "    if len(objects) != 1:\n",
    "        print(f\"Detected {len(objects)} objects in host!\")\n",
    "    i = max(list(range(len(objects))), key=lambda i: objects[\"cflux\"][i])\n",
    "    return objects[\"x\"][i], objects[\"y\"][i], objects[\"a\"][i], objects[\"b\"][i], objects[\"theta\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "host_ellipse = fit_ellipse(host_bayes_mean)\n",
    "print(host_ellipse)\n",
    "\n",
    "plot_asinh_stretch(host_bayes_mean)\n",
    "e = Ellipse(xy=(host_ellipse[0], host_ellipse[1]),\n",
    "                width=6*host_ellipse[2],\n",
    "                height=6*host_ellipse[3],\n",
    "                angle=host_ellipse[4] * 180. / np.pi)\n",
    "e.set_facecolor('none')\n",
    "e.set_edgecolor('red')\n",
    "plt.gca().add_artist(e)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eelr_bayes_mean.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# TODO: dynamically set this threshold\n",
    "thresh = 1\n",
    "center_x = host_bayes_mean.shape[1] / 2 - 0.5\n",
    "center_y = host_bayes_mean.shape[0] / 2 - 0.5\n",
    "thetas = []\n",
    "for r in range(eelr_bayes_mean.shape[0]):\n",
    "    for c in range(eelr_bayes_mean.shape[1]):\n",
    "        if eelr_bayes_mean[r, c] > thresh:\n",
    "            x = c - center_x\n",
    "            y = r - center_y\n",
    "            theta = math.atan2(y, x) - host_ellipse[4]\n",
    "            theta = theta * 180 / math.pi\n",
    "            if theta < 0:\n",
    "                theta += 360\n",
    "            thetas.append(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(thetas)\n",
    "plt.xlabel(\"Theta (Â°)\")\n",
    "plt.ylabel(\"Number of Pixels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polar_projection(img, center, Rmax=None, resolution=100):\n",
    "    \"\"\"Evaluate img at the location of polar grid coordinates\n",
    "    This method doesn't resample `img` on the polar grid, it merely\n",
    "    transforms the coordinates and picks the nearest pixel.\n",
    "    For resolved features, this is an acceptable approximation\n",
    "    \"\"\"\n",
    "    lims = img.shape\n",
    "    if Rmax is None:\n",
    "        Rmax = np.sqrt(lims[0]**2 + lims[1]**2)\n",
    "    R, P = np.meshgrid(np.linspace(0, Rmax, resolution, dtype=np.float), np.linspace(-np.pi, np.pi, resolution))\n",
    "    Y = np.round(R * np.sin(P)).astype('int') + center[0]\n",
    "    X = np.round(R * np.cos(P)).astype('int') + center[1]\n",
    "    YX = np.dstack((Y,X))\n",
    "    polar = np.array([[ img[tuple(coord)] for coord in YX[i]] for i in range(len(YX))]).T\n",
    "    return polar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 12  # number of angle bins\n",
    "angles_per_bin = 5  # number of angles to sample per bin\n",
    "\n",
    "eelr_polar = polar_projection(eelr_bayes_mean,\n",
    "                              (host_bayes_mean.shape[0] // 2, host_bayes_mean.shape[1] // 2),\n",
    "                              min(eelr_bayes_mean.shape[0] // 2 - 1, eelr_bayes_mean.shape[1] // 2 - 1),\n",
    "                              resolution=num_bins * angles_per_bin)\n",
    "\n",
    "# only consider pixels r_thresh or further from the center (units depend on polar resolution)\n",
    "r_thresh = 2\n",
    "angle_intensities = eelr_polar[r_thresh:].sum(axis=0)\n",
    "angle_intensities = np.array([sum(angle_intensities[i:i+angles_per_bin]) for i in range(0, num_bins*angles_per_bin, angles_per_bin)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cyclic_peak_inds(arr):\n",
    "    \"\"\"Finds peaks in a cyclic array.\"\"\"\n",
    "    \n",
    "    prom_thresh = 0.2 * (arr.max() - arr.min())  # min prominence of peaks\n",
    "#     dist_thresh = len(arr) // 2 - 1  # min distance between peaks\n",
    "    flattened_peaks, props = find_peaks(arr, prominence=prom_thresh)\n",
    "    if len(flattened_peaks) == 0:\n",
    "        return np.array([])\n",
    "    # rotate so that first peak is at front\n",
    "    left_roll = -props[\"left_bases\"][0]\n",
    "    left_rotated = np.roll(arr, left_roll)\n",
    "    left_rotated_peaks, _ = find_peaks(left_rotated, prominence=prom_thresh)\n",
    "    left_cyclic_peaks = (left_rotated_peaks - left_roll) % len(arr)\n",
    "    # rotate so that first peak is at end\n",
    "    right_roll = len(arr) - 1 - props[\"right_bases\"][0]\n",
    "    right_rotated = np.roll(arr, right_roll)\n",
    "    right_rotated_peaks, _ = find_peaks(right_rotated, prominence=prom_thresh)\n",
    "    right_cyclic_peaks = (right_rotated_peaks - right_roll) % len(arr)\n",
    "    return np.sort(np.union1d(left_cyclic_peaks, right_cyclic_peaks))\n",
    "\n",
    "def plot_with_peaks(arr, peak_inds, ax=None):\n",
    "    bar_colors = np.array([\"blue\"] * len(arr))\n",
    "    if len(peak_inds) > 0:\n",
    "        bar_colors[peak_inds] = \"red\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.bar(np.linspace(-np.pi, np.pi, len(arr)), arr, color=bar_colors, width=2*np.pi/len(arr))\n",
    "    ax.set_xlabel(\"Theta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclic_peak_inds = get_cyclic_peak_inds(angle_intensities)\n",
    "print(cyclic_peak_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_peaks(angle_intensities, cyclic_peak_inds)\n",
    "plt.savefig(f\"{prefix}angle_intensities.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df = pd.read_csv(\"parent_sample/FIRST.csv\", comment=\"#\")\n",
    "first_ids = first_df[\"objid\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_source_peaks(source_i, gen_fig=True):\n",
    "\n",
    "    # FIXME: scarlet breaks on 178\n",
    "    if source_i == 178: return []\n",
    "    \n",
    "    stretch = 1\n",
    "    Q = 5\n",
    "    norm = scarlet.display.AsinhMapping(minimum=0, stretch=stretch, Q=Q)\n",
    "    bands = ['g', 'r', 'i', 'z', 'y']\n",
    "    model_psf = scarlet.PSF(partial(scarlet.psf.gaussian, sigma=.8), shape=(None, 8, 8))\n",
    "    \n",
    "    # load in source\n",
    "    source_id = int(source_list[source_i][\"OBJID\"])\n",
    "    images, psfs = get_images_and_psfs(source_id)\n",
    "    catalog, segmap, bg_rms = makeCatalog(images)\n",
    "    mags = np.nan_to_num(source_list[source_i]['MAG_AB_LINEONLY'], nan=30.0)\n",
    "\n",
    "    # define scarlet frame and observation\n",
    "    frame = scarlet.Frame(images.shape, psfs=model_psf, channels=bands)\n",
    "    observation = scarlet.Observation(images, psfs=psfs, channels=bands).match(frame)\n",
    "\n",
    "    # sampling\n",
    "    num_samples = 20\n",
    "    eelr_host_ind = get_center_source(catalog, (images.shape[1], images.shape[2]))\n",
    "    unmasked_y_host_samples, unmasked_y_eelr_samples, unmasked_y_logL = get_unmasked_y_samples(catalog, eelr_host_ind, mags, num_samples, frame, observation)\n",
    "\n",
    "    # morphology Bayes mean and variance\n",
    "    host_morphs = np.array([sample.components[1].morph for sample in unmasked_y_host_samples])\n",
    "    # host_morphs = np.array([sample.morph for sample in unmasked_y_host_samples])\n",
    "    eelr_morphs = np.array([sample.morph for sample in unmasked_y_eelr_samples])\n",
    "    unmasked_y_logL = np.array(unmasked_y_logL)\n",
    "    mask = get_outliers(np.array(unmasked_y_logL))\n",
    "    scaled_likelihoods = np.exp(unmasked_y_logL[~mask] - min(unmasked_y_logL[~mask]))\n",
    "    scaled_likelihoods /= scaled_likelihoods.min()\n",
    "    host_morphs = host_morphs[~mask]\n",
    "    eelr_morphs = eelr_morphs[~mask]\n",
    "    host_bayes_mean, host_bayes_var = weighted_mean_and_var(host_morphs, scaled_likelihoods)\n",
    "    eelr_bayes_mean, eelr_bayes_var = weighted_mean_and_var(eelr_morphs, scaled_likelihoods)\n",
    "    \n",
    "    # zero out borders to remove artifacts due to PSF\n",
    "    zero_borders(host_bayes_mean)\n",
    "    zero_borders(eelr_bayes_mean)\n",
    "    \n",
    "    # low pass filter\n",
    "    eelr_bayes_mean_filtered = gaussian_filter(eelr_bayes_mean, sigma=2)\n",
    "\n",
    "    # EELR angle intensities\n",
    "    num_bins = 12  # number of angle bins\n",
    "    angles_per_bin = 5  # number of angles to sample per bin\n",
    "    eelr_polar = polar_projection(eelr_bayes_mean_filtered,\n",
    "                                  (host_bayes_mean.shape[0] // 2, host_bayes_mean.shape[1] // 2),\n",
    "                                  min(eelr_bayes_mean.shape[0] // 2 - 1, eelr_bayes_mean.shape[1] // 2 - 1),\n",
    "                                  resolution=num_bins * angles_per_bin)\n",
    "    # only consider pixels r_thresh or further from the center (units depend on polar resolution)\n",
    "    r_thresh = 2\n",
    "    angle_intensities = eelr_polar[r_thresh:].sum(axis=0)\n",
    "    angle_intensities = np.array([sum(angle_intensities[i:i+angles_per_bin]) for i in range(0, num_bins*angles_per_bin, angles_per_bin)])\n",
    "\n",
    "    # peaks in angle space\n",
    "    cyclic_peak_inds = get_cyclic_peak_inds(angle_intensities)\n",
    "\n",
    "    if gen_fig:\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5), gridspec_kw={'width_ratios': [1, 1.1, 1.2]})\n",
    "        fig.suptitle(f\"Source {source_id}\")\n",
    "        axs[0].set_title(\"Observation\")\n",
    "        axs[1].set_title(\"EELR Morphology\")\n",
    "        axs[2].set_title(\"EELR Angular Distribution\")\n",
    "        display_img(images, norm, catalog, axs[0])\n",
    "        im = axs[1].imshow(eelr_bayes_mean)\n",
    "        fig.colorbar(im, ax=axs[1], fraction=0.05)\n",
    "        plot_with_peaks(angle_intensities, cyclic_peak_inds, axs[2])\n",
    "        \n",
    "        # footnote\n",
    "        if source_i in first_ids:\n",
    "            footnote = \"In FIRST catalog.\"\n",
    "        else:\n",
    "            footnote = \"Not in FIRST catalog.\"\n",
    "        plt.figtext(0.1, 0.1, footnote, fontsize=\"small\", fontstyle=\"italic\", ha=\"left\", va=\"bottom\")\n",
    "#         plt.tight_layout(pad=2)\n",
    "        \n",
    "        prefix = f\"{source_id:05d}_\"\n",
    "        plt.savefig(f\"peak_outputs4/{prefix}peaks.png\", dpi=200, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "    \n",
    "    return cyclic_peak_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"full\"\n",
    "\n",
    "if sample == \"first\":\n",
    "    source_inds = first_ids\n",
    "elif sample == \"full\":\n",
    "    source_inds = range(len(source_list))\n",
    "\n",
    "peaks = Parallel(n_jobs=3, verbose=11)(delayed(get_source_peaks)(i) for i in source_inds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/Load Peak Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"peaks.npy\", peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = np.load(\"peaks.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with FIRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: consider distance between peaks?\n",
    "\n",
    "jetlikes = [source_inds[i] for i in range(len(source_inds)) if len(peaks[i]) == 2]\n",
    "print(len(jetlikes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_detected, _, first_detected_inds = np.intersect1d(jetlikes, first_ids, return_indices=True)\n",
    "print(f\"Detected {len(first_detected)} of {len(first_ids)} FIRST AGNs\")\n",
    "print(first_detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_missed = np.delete(first_ids, first_detected_inds)\n",
    "print(first_missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
